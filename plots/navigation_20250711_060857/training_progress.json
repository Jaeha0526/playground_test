{
  "config": {
    "num_timesteps": 1000000,
    "num_envs": 256,
    "learning_rate": 0.0003
  },
  "training_data": {
    "x": [
      0,
      204800,
      409600,
      614400,
      819200,
      1024000,
      1228800,
      1433600,
      1638400,
      1843200,
      2048000,
      2252800,
      2457600,
      2662400,
      2867200,
      3072000,
      3276800,
      3481600,
      3686400,
      3891200,
      4096000,
      4300800,
      4505600,
      4710400,
      4915200,
      5120000,
      5324800,
      5529600,
      5734400,
      5939200,
      6144000,
      6348800,
      6553600,
      6758400,
      6963200,
      7168000,
      7372800,
      7577600,
      7782400,
      7987200,
      8192000,
      8396800,
      8601600,
      8806400,
      9011200,
      9216000,
      9420800,
      9625600,
      9830400,
      10035200
    ],
    "y": [
      117.17655944824219,
      2426.337646484375,
      1542.040771484375,
      1599.844970703125,
      231.22833251953125,
      1448.294189453125,
      940.5340576171875,
      396.8346252441406,
      1013.9664916992188,
      2346.639892578125,
      184.35940551757812,
      570.253173828125,
      2021.656005859375,
      1446.736328125,
      1701.4007568359375,
      3374.639404296875,
      1512.335205078125,
      1695.1494140625,
      1188.946044921875,
      2023.229736328125,
      2588.819580078125,
      1802.92529296875,
      2932.5078125,
      1265.488037109375,
      1317.0523681640625,
      692.106201171875,
      2126.33349609375,
      1340.4923095703125,
      2145.078369140625,
      1015.5140380859375,
      499.9452209472656,
      2135.71142578125,
      1954.4964599609375,
      1910.7451171875,
      1021.7601928710938,
      1607.6470947265625,
      517.1337280273438,
      960.8448486328125,
      1707.62890625,
      2085.715087890625,
      2156.01171875,
      2762.22900390625,
      1003.0123901367188,
      756.1651000976562,
      1038.9423828125,
      446.819091796875,
      946.7628173828125,
      1693.587890625,
      1506.0880126953125,
      1796.693603515625
    ],
    "y_err": [
      1320.5108642578125,
      13631.0693359375,
      9211.3994140625,
      11329.908203125,
      2605.808837890625,
      8865.0908203125,
      8287.7939453125,
      4472.095703125,
      8935.65234375,
      12581.59765625,
      1795.7822265625,
      4756.60009765625,
      12825.4365234375,
      10283.421875,
      10558.06640625,
      14558.4736328125,
      8967.806640625,
      10132.01953125,
      8299.3525390625,
      12197.76171875,
      15141.064453125,
      11538.65234375,
      14734.1201171875,
      9724.6220703125,
      9678.525390625,
      4181.72998046875,
      10644.2626953125,
      7126.11572265625,
      11710.6923828125,
      5508.05224609375,
      3513.601318359375,
      12985.185546875,
      12653.65234375,
      12823.9638671875,
      8975.4677734375,
      9128.51953125,
      5757.2470703125,
      6471.3193359375,
      11240.61328125,
      11461.0615234375,
      11810.525390625,
      14082.275390625,
      6172.771484375,
      6849.0859375,
      5630.775390625,
      5035.39208984375,
      6492.8759765625,
      11800.2265625,
      9244.4404296875,
      10048.1572265625
    ]
  },
  "current_step": 10035200,
  "current_reward": 1796.693603515625,
  "best_reward": 3374.639404296875,
  "elapsed_time": "0:05:20.208733",
  "all_metrics": {
    "eval/walltime": 121.7908923625946,
    "training/sps": 83059.95787213271,
    "training/walltime": 157.35928344726562,
    "training/entropy_loss": -0.01942843571305275,
    "training/policy_loss": -0.00016043829964473844,
    "training/total_loss": 2288.84130859375,
    "training/v_loss": 2288.86083984375,
    "eval/episode_reward": 1796.693603515625,
    "eval/episode_reward/action_rate": -10.032537460327148,
    "eval/episode_reward/ang_vel_xy": -12.598090171813965,
    "eval/episode_reward/dof_pos_limits": 0.0,
    "eval/episode_reward/energy": -56.40192794799805,
    "eval/episode_reward/feet_air_time": 0.0,
    "eval/episode_reward/feet_clearance": -135.74139404296875,
    "eval/episode_reward/feet_height": 0.0,
    "eval/episode_reward/feet_slip": 0.0,
    "eval/episode_reward/goal_distance": -15.141731262207031,
    "eval/episode_reward/goal_reached": 89843.75,
    "eval/episode_reward/lin_vel_z": -2.427617073059082,
    "eval/episode_reward/orientation": -7.299619674682617,
    "eval/episode_reward/pose": 232.28431701660156,
    "eval/episode_reward/stand_still": -498.22509765625,
    "eval/episode_reward/termination": 0.0,
    "eval/episode_reward/torques": -7.309679985046387,
    "eval/episode_reward/tracking_ang_vel": 0.0,
    "eval/episode_reward/tracking_lin_vel": 0.0,
    "eval/episode_swing_peak": 13.43718433380127,
    "eval/episode_reward_std": 10048.1572265625,
    "eval/episode_reward/action_rate_std": 0.7709787487983704,
    "eval/episode_reward/ang_vel_xy_std": 2.3930623531341553,
    "eval/episode_reward/dof_pos_limits_std": 0.0,
    "eval/episode_reward/energy_std": 6.429738521575928,
    "eval/episode_reward/feet_air_time_std": 0.0,
    "eval/episode_reward/feet_clearance_std": 7.8920416831970215,
    "eval/episode_reward/feet_height_std": 0.0,
    "eval/episode_reward/feet_slip_std": 0.0,
    "eval/episode_reward/goal_distance_std": 6.358970642089844,
    "eval/episode_reward/goal_reached_std": 502458.0,
    "eval/episode_reward/lin_vel_z_std": 0.4522456228733063,
    "eval/episode_reward/orientation_std": 3.154566764831543,
    "eval/episode_reward/pose_std": 2.2006688117980957,
    "eval/episode_reward/stand_still_std": 30.324359893798828,
    "eval/episode_reward/termination_std": 0.0,
    "eval/episode_reward/torques_std": 0.22590892016887665,
    "eval/episode_reward/tracking_ang_vel_std": 0.0,
    "eval/episode_reward/tracking_lin_vel_std": 0.0,
    "eval/episode_swing_peak_std": 1.0125136375427246,
    "eval/avg_episode_length": 500.0,
    "eval/std_episode_length": 0.0,
    "eval/epoch_eval_time": 1.4285123348236084,
    "eval/sps": 44801.85325659275
  }
}